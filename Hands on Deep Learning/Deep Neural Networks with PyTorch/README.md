
## Ipython notebooks of [Deep Neural Networks with PyTorch](https://www.coursera.org/learn/deep-neural-networks-with-pytorch/home/welcome)
| # | **File name** |  **Description** |
| ---------- |--------- | ------------------------------------------------| 
|1|[1D_tensors](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/Deep%20Neural%20Networks%20with%20PyTorch/L1_1D_tensors.ipynb)| Basic operations on 1D tensors|
|2|[2D_tensors](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/Deep%20Neural%20Networks%20with%20PyTorch/L2_Two-Dimensional_Tensors.ipynb)| Basic operations on 2D tensors|
|3|[Derivatives](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/Deep%20Neural%20Networks%20with%20PyTorch/L3_derivativesandGraphsinPytorch.ipynb)| Derivatives in Pytorch|
|4|[Toy_dataset](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/Deep%20Neural%20Networks%20with%20PyTorch/L4_simple_data_set.ipynb)| Creating a toy dataset in Pytorch, compose and perform transformations on it|
|5|[Datasets_and_transforms](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/Deep%20Neural%20Networks%20with%20PyTorch/L5_Datasets_and_transforms.ipynb)| Build an image dataset object and perform pre-build transformations using torchvision.transforms on it|
|6|[MNIST_data_&_transforms](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/Deep%20Neural%20Networks%20with%20PyTorch/L6_pre-Built%20Datasets_and_transforms.ipynb)| How to use pre-built MNIST dataset and perform transformations on it|
|7|[Regression_prediction](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/Deep%20Neural%20Networks%20with%20PyTorch/L7_prediction_on_1D_input.ipynb)| Make predictions for multiple 1D inputs using linear class|
|8|[1D_Linear_regression_1_parameter](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/Deep%20Neural%20Networks%20with%20PyTorch/L8_linear_regression_one_parameter.ipynb)| Create linear regression model using 1 parameter, cost/criterion function using MSE, and plot parameters as well as loss values|
|9|[1D_Linear_regression_2_parameters](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/Deep%20Neural%20Networks%20with%20PyTorch/L9_training_slope_and_bias.ipynb)| 1D Linear regression model using 2 parameters (w and b). Visualize the data space and the parameter space during training via batch gradient descent|
|10|[Stochastic_gradient_descent](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/Deep%20Neural%20Networks%20with%20PyTorch/L10_stochastic_gradient_descent.ipynb)| 1D Linear regression using stochastic gradient descent|
|11|[Mini_batch_gradient_descent](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/Deep%20Neural%20Networks%20with%20PyTorch/L11_mini-batch_gradient_descent.ipynb)| 1D Linear regression using mini-batch gradient descent. This code also includes comparison between batch, stochastic and mini-batch gradient descent with different batch sizes|
|12|[Mini_batch_gradient_descent2](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/Deep%20Neural%20Networks%20with%20PyTorch/L12_PyTorchway.ipynb)| 1D Linear regression using  PyTorch build-in functions|
|13|[Models_with_different_LR](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/Deep%20Neural%20Networks%20with%20PyTorch/L13_Models_with_different_LR.ipynb)| 1D Linear regression with different learning rates and view results such as training and validation losses at different LR|
|14|[Multiple_linear_regression_prediction](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/Deep%20Neural%20Networks%20with%20PyTorch/L14_multiple_linear_regression_prediction.ipynb)| Multiple linear regression prediction (preparing forward propagation with 1xn tensor input)|
|15|[Multiple_linear_regression_training](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/Deep%20Neural%20Networks%20with%20PyTorch/L15_multiple_linear_regression_training.ipynb)| Multiple linear regression training with input of 1xn tensor|
|16|[Multi_target_linear_regression](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/Deep%20Neural%20Networks%20with%20PyTorch/L16_multi-target_linear_regression.ipynb)| Multiple target linear regression prediction (forward propagation)|
|17|[training_multiple_output_linear_regression](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/Deep%20Neural%20Networks%20with%20PyTorch/L17_training_multiple_output_linear_regression.ipynb)| pytorch build in functions to train multiple target linear regression|
|18|[logistic_regression_prediction](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/Deep%20Neural%20Networks%20with%20PyTorch/L18_logistic_regression_prediction.ipynb)| Prediction using sigmoid/logistic function|
|19|[logistic_regression_prediction](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/Deep%20Neural%20Networks%20with%20PyTorch/L19_Bad_initialization_logistic_regression_with_mean_square_error.ipynb)| Illustration of poor performance of logistic regression via bad parameters initialization|
|20|[Softmax_in_1D](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/Deep%20Neural%20Networks%20with%20PyTorch/L20_softmax_in_1D.ipynb)| Building a Softmax classifier in 1D|
|21|[predicting_MNIST_using_Softmax](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/Deep%20Neural%20Networks%20with%20PyTorch/L21_predicting_MNIST_using_Softmax.ipynb)| Classify handwritten digits from the MNIST database by using Softmax classifier and visualize parameters learned for each class following model training|
|22|[simpleNN_1hiddenlayer](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/Deep%20Neural%20Networks%20with%20PyTorch/L22_simpleNN_1hiddenlayer.ipynb)| Simple Neural Network with 1 hidden layer|
|23|[NN_more_hidden_neurons](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/Deep%20Neural%20Networks%20with%20PyTorch/L23_NN_more_hidden_neurons.ipynb)| Neural Networks with 1 hidden layer (more neurons)|
|24|[Neural_networks](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/Deep%20Neural%20Networks%20with%20PyTorch/L24_Neural_network.ipynb)| Building a neural network with 1 hidden layer to classify noisy XOR data|
|25|[1_layer_neural_network_MNIST](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/Deep%20Neural%20Networks%20with%20PyTorch/L25_1layer_neural_network_MNIST.ipynb)| Neural networks with 1 hidden layer to classify MNIST data|
|26|[Activation_function](https://github.com/ruchikaverma-iitg/ML-DL-RL_Codes/blob/master/Hands%20on%20Deep%20Learning/Deep%20Neural%20Networks%20with%20PyTorch/L26_activation_function.ipynb)| How to apply different Activation functions in Neural Network|

